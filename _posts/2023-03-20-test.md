---
layout: single
title: "Test page"
excerpt: 
date: 2023-03-20 08:00:00 -0800
toc: true
categories: research
comments:
  host: mastodon.world
  username: pwintz
  id: 
---
<!-- <script>window.MathJax = { }; </script> -->
{% raw %} 
$$
% Define macros.
\def\reals{\mathbb{R}}
\def\realsn{\reals^n}
\def\safe{{\mathbf{Safe}}}
\def\Unsafe{{\mathbf{Unsafe}}}
\def\Init{{\mathbf{Init}}}
$$
{% endraw %}

Consider a differential equation 

$$\dot x = f(x)$$ 

that evolves on a domain $$x \in \reals^n.$$
 <!-- and has (unknown) disturbances in $$d \in D.$$  -->
Suppose there is an unsafe set $$\Unsafe \subset \reals^n.$$
 <!-- (presumably, $$\Unsafe \cap C \neq \emptyset,$$ otherwise the following work is not interesting.) -->
We want to be able to show that every solution to the ODE does not enter the unsafe set.  
In particular, for every solution $$t \mapsto \phi(t)$$ to the ODE that starts in the set $$X_0$$ (with $$X_0 \cap \Unsafe = \emptyset$$), $$\phi$$ never enters $$\Unsafe.$$

In particular, we want to show $$\safe := \reals^n \setminus \Unsafe$$ is forward invariant. 
One common approach is to construct a _barrier function_ $$B : \reals^n \to \reals$$ that satisfies
- (B1) $$B$$ is differentiable.
- (B2) $$B(x)>0 \quad \forall x \in \Unsafe $$
- (B3) $$B(x) \leq 0 \quad \forall x \in \Init$$
- (B4) $$\langle \nabla B(x), f(x)\rangle \leq 0 \quad \forall x \in \reals^n \text { such that } B(x)=0$$
<!-- - (B4) $$\frac{\partial B}{\partial x}(x) f(x, d) \leq 0 \quad \forall(x, d) \in \reals^n \times D \text { such that } B(x)=0$$ -->

The function $$x \mapsto \langle \nabla B(x), f(x)\rangle$$ is the rate of change of $$B$$ as $$x$$ evolves along $$f.$$ Some authors write it as $$\frac{\partial B}{\partial x}(x) f(x)$$ or $$L_f B(x).$$

If such a barrier function exists, then the system is safe {% cite prajna_safety_2004 --label <> --locator Theorem 1 %}. 
The difficulty is actually generating the barrier functions. 
In general, this is a hard problem. 
With certain assumptions, however, we can use efficient numerical algorithms to solve it. 

## Assumptions To Make The Problem Tractable

First, we replace (B4) with
- (B4') $$\langle \nabla B(x), f(x)\rangle \leq 0 \quad \forall x \in \reals^n.$$
<!-- - (B4') $$\frac{\partial B}{\partial x}(x) f(x, d) \leq 0 \quad \forall(x, d) \in \reals^n \times D.$$ -->

In words, we are replacing condition (B4) that requires that $$B$$ is nonincreasing on the boundary of $$\Unsafe$$ with a condition that $$B$$ is nonincreasing _everywhere_.
This is significantly more restrictive but aids in the computation because the set of functions that satisfy (B1-3) and (B4') is convex (that is, taking the weighted average of any two such functions, added pointwise, produces another function that also satisfies (B1-3) and (B4')). 

Suppose, additionally, that $$f$$ is polynomial. 
That is, each component of $$f$$ can be written as a polynomial. 
Suppose, also, that the sets $$D$$ and $$\Unsafe$$ are semialgebriac set. A set is called semialgebraic if it is a finite union of sets defined by polynomial equalities and polynomial inequalities. 

<!-- <h4>Example: Semialgebraic Set in \(\reals^2\)</h4> -->
For example, the set 

$$\begin{aligned}
  &\{(x_1, x_2) \in \reals^2 \mid x_2^4 - x_1^2 + 3 x_1 x_2 - 1 \geq 0\} \\ 
  &{}\cup \{(x_1, x_2) \in \reals^2 \mid x_2^2 + x_1 - 1 = 0\} 
\end{aligned}$$ 

is a semialgebraic set in $$\reals^2$$.

Under these assumptions, we also assume that $$B$$ is a polynomial. (The degree of the polynomial remains to be determined).

A concept we will use is sum of squares. A polynomial $$p : \reals^n \to \reals $$ is a _sum of squares_ if there exist polynomials $$p_1, p_2, \dots, p_m$$ such that 

$$p(x) = \sum_{i=1}^m p_i^2(x) \quad \text{for all } x \in \reals^n.$$ 

Every sum of squares is positive semidefinite. 

## Equivalence Between Polynomial Positive Definiteness and Matrix Positive Definitenesss

Working with polynomials directly is difficult. 
It is easier to work with matrices. 
Thankfully, every polynomial $$z \mapsto p(z)$$ can be written as $$[z \mapsto z^\top A z$$ for some square matrix $$A$$. 
<!-- TODO: Clean up! -->
This is called the _Square Matrix Representation_ (SMR) of $$$$ by (Wang et al., 2018) and (Chesi, 2011).
A polynomial can always be written as a sum of monomials, such as, 

$$p(x, y) = a + b x + c y + d xy + e x^2 + f y^2.$$ 

For simplicity, suppose that $$p$$ has an even degree $$d$$. We only care about polynomials of even degree because our goal is to find positive definite polynomials and odd polynomials are never positive definite. 
For $$x = (x_1, x_2, \dots, x_n),$$ let $$[x]_{d/2}$$ be a vector containing every monomial formed from components of $$x$$ with a degree less than or equal to $$d/2.$$ 
The order of the monomials in $$[x]_{d/2}$$ are not important so long as the order is consistent.
For $$n=2$$ and $$d=4$$, 

$$[x]_{2} = (1, x_1, x_2, x_1x_2, x_1^2, x_2^2).$$

<!-- The dimension of $$[x]_{d/2}$$ is $$(n + d/2) \text{ choose } n$$? -->

We can then generate any polynomial $$p$$ of degree $$d$$ in $$n$$ variables by picking an appropriate square matrix $$A = [a_{ij}]$$ such that

$$
p(x) = [x]_{d/2}^\top A [x]_{d/2}
$$

Continuing the example for $$n=2$$ and $$d=4$$,

$$[x]_{2}^\top A [x]_{2} 
= \begin{aligned} 
a_{00} + a_{01} x_1 + {} &\cdots + a_{05}x_1^2 + a_{06}x_2^2 \\ 
{} + {}a_{10}x_1 + a_{11} x_1^2 + {} &\cdots + a_{15}x_1^3 + a_{16}x_1x_2^2 \\ 
& \vdots \\ 
{} + a_{50}x_1^2 + a_{51} x_1^3 + {} &\cdots + a_{55}x_1^4 + a_{56}x_1^2x_2^2.
\\ 
{} + a_{60}x_2^2 + a_{61} x_1 x_2^2 + {} &\cdots + a_{65}x_1^2x_2^2 + a_{66}x_2^4.
\end{aligned}$$

We see that several monomials appear multiple times with different coefficients. 
In particular $$x_1^2$$ is appears in the terms $$a_{05}x_1^2$$ and $$a_{11}x_1^2$$.
This indicates that $$A$$ is not unique for a given polynomial.
Note, however, that the coeffiecients of each monomial in the resulting sum come from symmetric elements of $$A$$ (or skew-diagonal elements). 
For instance, the coefficients of $$x_1$$ are $$a_{01}$$ and $$a_{10}$$, the coefficients of $$x_1^2$$ are $$a_{05}$$ and $$a_{50}$$ (and $$a_{11}$$), and so on. 
This allows us to pick $$A$$ such that it is symmetric.

Symmetric matrices have nice properties that we exploit. Suppose $$A$$ is positive semidefinite and we pick $$A$$ to be symmetric (the actual process of picking $$A$$ to be symmetric is described later). 
Then, we can use Cholesky decomposition to factor $$A$$ into the product of an upper triangular matrix $$U$$ and its transpose $$U^\top,$$ as follows:

$$A = U^\top U.$$

Using this decomposition, the square matrix representation $$[x]_{d/2}^\top A [x]_{d/2}$$ can be written as 

$$[x]_{d/2}^\top A [x]_{d/2} = ([x]_{d/2}^\top U^\top)(U [x]_{d/2}) = \|U [x]_{d/2}\|^2.$$

Each entry in the vector $$U [x]_{d/2}$$ is a polynomial. The squared euclidean norm $$\|\cdot\|^2$$ maps a vector to the squared sum of its entries. Therefore, $$\|U [x]_{d/2}\|^2$$ is a sum–of–squares polynomial.

## Verify that a Polynomial is Positive Semidefinite
Suppose we have a polynomial $$p$$, and we want to determine whether $$p$$ is positive semidefinite. 
To do so, we will try to find a positive semidefinite $$A$$ such that $$p(x) = [x]_{d/2}^\top A [x]_{d/2}$$
<!-- TODO: We need to define positive (semi)definite and the notation \succeq. -->
We can write the findings of the previous section as a semidefinite programming problem. We want to find $$A$$ such that 
$$A \succeq 0 \text{ and } p = [x]_{d/2}^\top A [x]_{d/2}.$$
The right-hand equation generates a set of affine constraints because the coefficients of each monomial in $$p$$ must equal the sum of the coefficients of the matching monomials in $$[x]_{d/2}^\top A [x]_{d/2}.$$

### Example
We will look at a polynomial for the case $$n=2$$ and $$d=2$$. In particular, let's consider 

$$(x_1, x_2) \mapsto p(x_1, x_2) = c_1 + c_2 x_1 + c_3 x_2 + c_4 x_1^2 + c_5  x_1x_2 + c_6 x_2^2.$$

<!-- (Notice that $$p$$ has six terms and $$\binom{n+d}{d} = \binom{4}{2} = 6.$$) -->

We choose to write $$[x]_{d/2}$$ as

$$[x]_{d/2} = (1, x_1, x_2).$$

Let $$A = [a_{ij}]$$ be a $$3\times 3$$ matrix. The expansion of the Square Matrix Representation (SMR) is 

$$\begin{align*}
[x]_{d/2}^\top A [x]_{d/2} 
&= a_{00} + a_{01} x_1 + a_{02}x_2 \\ 
  &\quad{}+{} a_{10}x_1 + a_{11} x_1^2 + a_{12}x_1x_2 \\ 
  &\quad{}+{} a_{20}x_2 + a_{21} x_1x_2 + a_{22}x_2^2.
 \\
&= a_{00} + (a_{01} + a_{10}) x_1 + (a_{02} + a_{20})x_2 \\
  &\quad{} + a_{11} x_1^2 + (a_{12} + a_{21}) x_1x_2 + a_{22}x_2^2
\end{align*}$$

This gives six affine constraints:

$$\begin{align*}
a_{00} &= c_1 \\ 
a_{01} + a_{10} &= c_2 \\ 
a_{02} + a_{20} &= c_3 \\ 
a_{11} &= c_4 \\ 
a_{12} + a_{21} &= c_5 \\ 
a_{22} &= c_6.
\end{align*}$$

Because we want $$A$$ to be symmetric, we assume $$a_{01} = a_{10}$$,  $$a_{02} = a_{20}$$, and $$a_{12} = a_{21}$$. By substitution, we find a simplified version of the constraints. 

$$\begin{align*}
a_{00} &= c_1 \\ 
2a_{01} &= c_2 \\ 
2a_{02} &= c_3 \\ 
a_{11} &= c_4 \\ 
2a_{12} &= c_5 \\ 
a_{22} &= c_6.
\end{align*}$$

To make the example more concrete, let $$x \mapsto p(x) := 2 - x_1 + 4x_1x_2 + 5 x_2^2.$$

Then, the simplified constraints are 

$$\begin{align*}
a_{00} &= 0 \\ 
2a_{01} &= -1 \\ 
2a_{02} &= 0 \\ 
a_{11} &= 0 \\ 
2a_{12} &= 4 \\ 
a_{22} &= 5.
\end{align*}$$

The values of $$a_{01},$$ $$a_{02},$$ and $$a_{11}$$ are zero so they can be excluded from the consideration and we are left with three constraints that we need to satisfy. We put them into a standard form where $$0$$ is on the right-hand side of the equation. The semidefinite program that we need to solve is therefore written as

$$\begin{align*}
\operatorname*{minimize}_{h}
2a_{01} + 1 &= 0 \\ 
2a_{12} - 4 &= 0 \\ 
 a_{22} - 5 &= 0.
\end{align*}$$

### Setting Up CVX
See [here](http://cvxr.com/cvx/doc/install.html) for how to install CVX. 

```
coefficients = [100, -1, 0, 1, 4, 5]';
monomials = @(x1, x2) [1; x1; x2; x1^2; x1*x2; x2^2];
polynomial = @(x1, x2) sum(coefficients.*monomials(x1, x2));

n = 3;
% "sdp" is important to enable semidefininite programming! 
% http://cvxr.com/cvx/doc/sdp.html
cvx_begin sdp 
    variable A(n, n)
    subject to
        A >= 0; % Require A to be symmetric positive semidefinite.
          A(1, 1) == coefficients(1);
        2*A(1, 2) == coefficients(2);
        2*A(1, 3) == coefficients(3);
          A(2, 2) == coefficients(4);
        2*A(2, 3) == coefficients(5);
          A(3, 3) == coefficients(6);
cvx_end

% Check that all of the eigenvalues are nonnegative.
assert(all(eig(A) >= 0))

% Check that random points always make the polynomial and the Z'AZ equal and
% positive.
for x = rand(2, 100)
    p_of_x = polynomial(x(1), x(2));
    Z = [1; x(1); x(2)];
    assert(p_of_x >= 0)
    assert(Z'*A*Z >= 0)
    fprintf('%.2e\n', Z'*A*Z - p_of_x)
end
```

## Generate a Positive Semidefinite Polynomial

## Use Semidefinite Programming to Generate Barrier Function 

In many cases, we need to generate a barrier function from a given system.

To allows us to use SOS programming to generate a barrier function, we need to describe the initial set $$\Init$$ and the unsafe set $$\Unsafe$$ using polynomials. 
In particular, let $$g_\Init : \reals^n \to \reals^{m_\Init}$$ be vector-valued function such that each component is defined by a polynomial and 

$$\Init = \{x \in \realsn \mid g_\Init(x) \geq 0\}.$$

For a vector $$v,$$ the inequality $$v \geq 0$$ indicates that each element of $$v$$ is greater than or equal to zero.

Similarly, let $$g_\Unsafe : \reals^n \to \reals^{m_\Unsafe}$$ be vector-valued polynomial function such that 

$$\Unsafe = \{x \in \realsn \mid g_\Unsafe(x) \geq 0\}.$$

### How to translate general semialgebraic sets into standard form
We enumerate rules for rewriting semialgebraic sets into the form $$\{x \in \realsn \mid h(x) \geq 0\}$$
- $$\{x \in \realsn \mid h_1(x) \geq 0, h_2(x) \geq 0\} \implies \left\{x \in \realsn : \begin{bmatrix} h_1(x) \\ h_2(x) \end{bmatrix} \geq 0\right\}$$
- $$\{x \in \realsn \mid h_1(x) \geq 0 \text{ or } h_2(x) \geq 0\} \implies $$ ???
- $$\{x \in \realsn \mid \underline{\ell} \leq h(x) \leq \overline{\ell}\} \implies \left\{x \in \realsn \mid \big(h(x) - \underline{\ell}\big)\big(\overline{\ell} - h(x)\big) \geq 0 \right\}$$

### Theoretical Result
**Proposition ({% cite prajna_safety_2004 --label <> --locator Proposition 3 %}).** <i>Let the continuous system $$\dot x = f(x)$$ and the descriptions of all the sets $$\Init$$ and $$\Unsafe$$ be given. Suppose there exist polynomials $$x \mapsto B(x)$$ and $$x\mapsto \lambda(x)$$, a positive number $$\epsilon$$, and vectors of sums of squares $$x \mapsto \sigma_{\Unsafe}(x)$$ and $$x \mapsto \sigma_{\Init}(x)$$,
such that the following functions are sums of squares:

$$
\begin{aligned}
x \mapsto & B(x)-\epsilon-\langle \sigma_{\Unsafe}(x), g_{\Unsafe}(x)\rangle \\
x \mapsto & -B(x)- \langle \sigma_{\Init}(x), g_{\Init}(x)\rangle \\
x \mapsto & -\langle \nabla B(x), f(x)\rangle - \lambda(x) B(x) \\
\end{aligned}
$$

<i>Then $$B(x)$$ satisfies (B1-B4).

<!-- PROOF Given the assumptions in the above proposition, for all $$x \in\realsn$$

$$\begin{aligned} 
B(x) - \langle \sigma_{\Unsafe}(x), g_{\Unsafe}(x)\rangle \geq \epsilon \\
-B(x) - \langle \sigma_{\Init}(x), g_{\Init}(x)\rangle \geq 0 \\
-\langle \nabla B(x), f(x)\rangle - \langle \sigma_{I}(x), g_{I}(x)\rangle - \lambda(x) B(x) \geq 0
\end{aligned}$$ -->

For a control system $$\dot x = f(x, u)$$, the process is similar, except that it is necessary to simulatneously design a control law $$u = \kappa(x)$$. 
Suppose $$f$$ is a given polynomial in $$x$$ and $$u$$ and $$\kappa$$ is a polynomial in $$x$$ that needs to be determined.
Then, the last function in {% cite prajna_safety_2004 --label <> --locator Proposition 3 %} is replaced by 

$$
x \mapsto -\langle \nabla B(x), f(x, \kappa(x))\rangle - \lambda(x) B(x).
$$

Because $$f$$ and $$\kappa$$ are polynomials, their composition $$x \mapsto f(x, \kappa(x))$$ is also a polynomial.

### Example
Consider the system with $$x \in \reals^4$$ and $$u \in \reals^2$$ given by

$$
\dot x = f(x, u) = \begin{bmatrix} 
  x_3 \\
  x_4 \\
  x_1^2 - x_4u_1^2 \\
  u_2(x_3 - x_2)
\end{bmatrix}
$$

Let 

$$\Init := \{(x_1, x_2, x_3, x_4) \in \reals^4 \mid x_1 \leq -10 \text{ or } x_1 \geq 10\}$$

and 

$$\Unsafe := \{(x_1, x_2, x_3, x_4) \in \reals^4 \mid x_1 = 0, x_2 \leq 0 \}.$$

Polynomials that define $$\Init$$ and $$\Unsafe$$ are given for all $$x = (x_1, x_2, x_3, x_4) \in \reals^4$$ as $$g_\Init(x) = x_1^2 - 100$$ and $$g(x)_\Unsafe := (-x_1^2, -x_2).$$

Then, we want to find a real number $$\epsilon > 0$$ and polynomials $$B$$, $$\kappa$$, $$\lambda$$, $$\sigma_\Unsafe$$ and $$\sigma_\Init$$ that solves the following optimization problem:

$$
\begin{aligned}
\operatorname{minimize} \quad & \epsilon \\
\operatorname{subject to} \quad 
  & \epsilon > 0 \\ 
  & \text{The following are sums of squares:} \\ 
  & \sigma_\Unsafe \\
  & \sigma_\Init \\
  & x \mapsto B(x)-\epsilon-\langle \sigma_{\Unsafe}(x), g_{\Unsafe}(x)\rangle \\
  & x \mapsto -B(x)- \langle \sigma_{\Init}(x), g_{\Init}(x)\rangle \\
  & x \mapsto -\langle \nabla B(x), f(x, \kappa(x))\rangle - \lambda(x) B(x).
\end{aligned}
$$

 

### Notes on setting up SOSSOLVER. 
It doesn't seem to work with Mosek. Try [https://github.com/sqlp/sedumi](SeDuMi), which is open source and actively maintained.




### Notes on generating Control Laws and Barrier Functions

# Further Reading
- {% cite duan_computational_2023 %} [This paper provides a way to generate control barrier functions for control-affine feedback systems.]
- {% cite prajna_safety_2004 %}
  [This paper introduces barrier functions for hybrid systems. It gives a rough sketch of how to use sum of squares programming to generate barrier functions that served as a roadmap for this guide.]
- {% cite sloth_existence_2012 %} [Describes a way to simplify complicated systems with multiple components so that barrier functions can be found for individual subcomponents separately.]
- {% cite wang_permissive_2018 %} [Introduces techniques that allow for synthesizing better barrier functions in the sense that the]
- {% cite noauthor_getting_nodate %} Page with links for various tools for working with SOS's in various languages. 

# Bibliography
{% bibliography --cited %}